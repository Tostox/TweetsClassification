{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Classification for recommendation engine  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this work is to build predictive models that can automatically infer people’s needs from user- generated content. Specifically, we want to analyze text data from social media in order to build a recommender system. The engine can be able to recognize a specific need or pattern inside the data and suggest a product to sell. For example, we suppose to analyze data from twitter and try to identify people who want to travel in the future (or who are a \"traveller\") and suggest them a travel-related products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main issues in NLP problems like this is that we not have a collection of labelled examples as training set. That’s why data labeling is usually the bottleneck in developing NLP applications and keeping them up-to-date. Can be very hard to labelling a lot of tweets and the training step require a  thousands of labeled examples. Also we have to decide how extract the data from the social source in order to create a dataset that can be a \"true\" representation of a real context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by define a set of heuristic rule to use in the Twitter API to obtain the data. We use for example the high level descriptions of travel-correleted products to extract an array of keywords that can be associated to the \"traveller world\". We use this list of words combined with other specific patterns (or regular expressions) to build a set of rules. By using the Twitter API we extract some thousands of tweets travel-related and other tweet that can be labelled as \"general\" because extracted with no rules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this data we can try to build a classifier by combining weak supervision and data augmentation/pseudo labelling techniques. We follow this 4 step:\n",
    "* collect a small number of manual labeled examples;\n",
    "* use the back translation as data augmentation technique to increse the number of labeled example in the training set;\n",
    "* build a weak binary classifier using the basic ML models (Multinomial Naïve Bayes and Logistic Regression);\n",
    "* classify the data in the unlabeled set and repeat the process to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/training_construction.png\" height=\"700\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"data/training_travel.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>15028</td>\n",
       "      <td>did scomo really just get a ‘lifeline bounce’ ...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>31355</td>\n",
       "      <td>shit tastes like GARBAGE but the trip? beautif...</td>\n",
       "      <td>general_travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>29098</td>\n",
       "      <td>Winter comes in many guises in Europe – in the...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>4446</td>\n",
       "      <td>so uk is leaving eu by end of march by default...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>37269</td>\n",
       "      <td>We shall be going! Adventure Travel Show retur...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text           label\n",
       "1897  15028  did scomo really just get a ‘lifeline bounce’ ...         general\n",
       "1106  31355  shit tastes like GARBAGE but the trip? beautif...  general_travel\n",
       "342   29098  Winter comes in many guises in Europe – in the...          travel\n",
       "1926   4446  so uk is leaving eu by end of march by default...         general\n",
       "28    37269  We shall be going! Adventure Travel Show retur...          travel"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1986, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in this training set we have tweets labeled as \"general\" and other labeled as \"general travel\". This is due by the fact that we have some tweets in our training set that are releted to the topics \"travel\" but are not what we are searching.\n",
    "For example, some people can write about the journey of someone else, a third part like some friend or a famous person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(data=training, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model we cleaned the text by removing all the special character and stopwords. Also, we extract the lemma of each tokens in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining import TextPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessing(lemmatization = True, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tp_travel.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tp, 'tp_travel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning...\n",
      "Standardization...\n",
      "Tokenization...\n",
      "Removing stopwords...\n",
      "Lemmatization...\n",
      "Finish\n",
      "CPU times: user 25min 1s, sys: 3min 36s, total: 28min 38s\n",
      "Wall time: 28min 26s\n"
     ]
    }
   ],
   "source": [
    "%time training_clean = tp.fit(training, \"text\", min_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>15028</td>\n",
       "      <td>did scomo really just get a  lifeline bounce  ...</td>\n",
       "      <td>general</td>\n",
       "      <td>[scomo, really, get, lifeline, bounce, polls, ...</td>\n",
       "      <td>[scomo, really, get, lifeline, bounce, poll, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>31355</td>\n",
       "      <td>shit tastes like garbage but the trip  beautif...</td>\n",
       "      <td>general_travel</td>\n",
       "      <td>[shit, tastes, like, garbage, trip, beautiful,...</td>\n",
       "      <td>[shit, taste, like, garbage, trip, beautiful, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>29098</td>\n",
       "      <td>winter comes in many guises in europe   in the...</td>\n",
       "      <td>travel</td>\n",
       "      <td>[winter, comes, many, guises, europe, north, s...</td>\n",
       "      <td>[winter, come, many, guise, europe, north, ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>4446</td>\n",
       "      <td>so uk is leaving eu by end of march by default...</td>\n",
       "      <td>general</td>\n",
       "      <td>[leaving, end, march, default, settings, curio...</td>\n",
       "      <td>[leave, end, march, default, setting, curious,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>37269</td>\n",
       "      <td>we shall be going  adventure travel show retur...</td>\n",
       "      <td>travel</td>\n",
       "      <td>[shall, going, adventure, travel, show, return...</td>\n",
       "      <td>[shall, go, adventure, travel, show, return, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text  \\\n",
       "1897  15028  did scomo really just get a  lifeline bounce  ...   \n",
       "1106  31355  shit tastes like garbage but the trip  beautif...   \n",
       "342   29098  winter comes in many guises in europe   in the...   \n",
       "1926   4446  so uk is leaving eu by end of march by default...   \n",
       "28    37269  we shall be going  adventure travel show retur...   \n",
       "\n",
       "               label                                             tokens  \\\n",
       "1897         general  [scomo, really, get, lifeline, bounce, polls, ...   \n",
       "1106  general_travel  [shit, tastes, like, garbage, trip, beautiful,...   \n",
       "342           travel  [winter, comes, many, guises, europe, north, s...   \n",
       "1926         general  [leaving, end, march, default, settings, curio...   \n",
       "28            travel  [shall, going, adventure, travel, show, return...   \n",
       "\n",
       "                                                  lemma  \n",
       "1897  [scomo, really, get, lifeline, bounce, poll, a...  \n",
       "1106  [shit, taste, like, garbage, trip, beautiful, ...  \n",
       "342   [winter, come, many, guise, europe, north, ser...  \n",
       "1926  [leave, end, march, default, setting, curious,...  \n",
       "28    [shall, go, adventure, travel, show, return, o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test (validation set or Held-out set) split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with oversample techniques and feature extraction, is important to split the training data into two sample: one for select the best model configuration and one (the held-out) for the performance evaluation. In this case we use the 80% of our data for training and the 20% for the validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_clean, training_clean[\"label\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1588, 5) (398, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_class(label):\n",
    "    if label == 'general_travel':\n",
    "        return 'general'\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['label'] = X_train['label'].apply(rename_class)\n",
    "X_test['label'] = X_test['label'].apply(rename_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.apply(rename_class)\n",
    "y_test = y_test.apply(rename_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general    1120\n",
       "travel      468\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general    273\n",
       "travel     125\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a classifier using the augmented training set  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the class in our training set are unbalanced, in order to improve the performance of our classifier, it's a good choice to resample the minority class. For do this, we try to apply a data augmentation techniques. \n",
    "An effective method is to augment the training corpus with back-translations of target language sentences. In this case we use a very simplified version of this method and we select a two random samples of example and back translated these senteces in two different languages.\n",
    "Then we add these syntethic example to our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples = pd.read_csv(\"data/training_travel_bt_1_en_zh-tw.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples = new_examples[['index', 'text', 'label']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning...\n",
      "Standardization...\n",
      "Tokenization...\n",
      "Removing stopwords...\n",
      "Lemmatization...\n",
      "Finish\n",
      "CPU times: user 3min, sys: 25.8 s, total: 3min 26s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%time new_examples = tp.fit(new_examples, \"text\", min_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = pd.concat([X_train, new_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning...\n",
      "Standardization...\n",
      "Tokenization...\n",
      "Removing stopwords...\n",
      "Lemmatization...\n",
      "Finish\n",
      "CPU times: user 3min 15s, sys: 28.2 s, total: 3min 44s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "new_examples = pd.read_csv(\"data/training_travel_bt_1_en_he.csv\", index_col=False)\n",
    "new_examples = new_examples[['index', 'text', 'label']].dropna()\n",
    "%time new_examples = tp.fit(new_examples, \"text\", min_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = pd.concat([X_train_augmented, new_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(data=X_train_augmented, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to obtain the features matrix. For our simple first model we want to use a Bag of Words representation, coding each lemma by using the TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining.text_preprocessing import VectorizeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_toVect = VectorizeData(method='tf-idf')\n",
    "train, test, vectorizer = token_toVect.fit(X_train_augmented[\"lemma\"], X_test[\"lemma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(X_train_augmented['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fittig a ML model using k-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to fit a ML model to predict the label of the given tweet using the Bag Of Word sparse matrix and TF-IDF. We test a Multinomial Naïve Bayes and a Logistic Regression on 10-fold cross validation. The best parameters configuration was obtained using a grid search and the F1 measure as loss function to maximize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.evaluateModels import CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidation(models=[\"MultinomialNB\", \"LogisticRegression\"], \n",
    "                     scores = [\"auc\", \"mcc\", \"f1\", \"recall\", \"precision\"],\n",
    "                     params_file = \"./param_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Searching the best MultinomialNB with grid search cv...\n",
      "\n",
      "Best_estimator: MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
      "\n",
      "Best_scores: 0.7994459351963976\n",
      "Evaluate the best model configuration with a new cross validation...\n",
      "\n",
      "Model: LogisticRegression\n",
      "Searching the best LogisticRegression with grid search cv...\n",
      "\n",
      "Best_estimator: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best_scores: 0.8154035194373602\n",
      "Evaluate the best model configuration with a new cross validation...\n",
      "\n",
      "Finish\n",
      "CPU times: user 806 ms, sys: 130 ms, total: 937 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%time res, model = cv.fit_cv(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>MultinomialNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>computation_total</th>\n",
       "      <td>0.0542715</td>\n",
       "      <td>0.0378113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc_mean</th>\n",
       "      <td>0.835612</td>\n",
       "      <td>0.801748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc_sd</th>\n",
       "      <td>0.0630007</td>\n",
       "      <td>0.0642807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc_ci_95%</th>\n",
       "      <td>[0.8206, 0.8506]</td>\n",
       "      <td>[0.7864, 0.8171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc_ci_99%</th>\n",
       "      <td>[0.814, 0.8572]</td>\n",
       "      <td>[0.7797, 0.8238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc_mean</th>\n",
       "      <td>0.937644</td>\n",
       "      <td>0.978924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc_sd</th>\n",
       "      <td>0.00383383</td>\n",
       "      <td>0.00182915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc_ci_95%</th>\n",
       "      <td>[0.9367, 0.9386]</td>\n",
       "      <td>[0.9785, 0.9794]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc_ci_99%</th>\n",
       "      <td>[0.9363, 0.939]</td>\n",
       "      <td>[0.9783, 0.9796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mcc_mean</th>\n",
       "      <td>0.677811</td>\n",
       "      <td>0.613374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mcc_sd</th>\n",
       "      <td>0.115897</td>\n",
       "      <td>0.13499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mcc_ci_95%</th>\n",
       "      <td>[0.6502, 0.7054]</td>\n",
       "      <td>[0.5812, 0.6456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mcc_ci_99%</th>\n",
       "      <td>[0.6381, 0.7175]</td>\n",
       "      <td>[0.5671, 0.6596]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mcc_mean</th>\n",
       "      <td>0.875453</td>\n",
       "      <td>0.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mcc_sd</th>\n",
       "      <td>0.00737948</td>\n",
       "      <td>0.00372086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mcc_ci_95%</th>\n",
       "      <td>[0.8737, 0.8772]</td>\n",
       "      <td>[0.9549, 0.9566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mcc_ci_99%</th>\n",
       "      <td>[0.8729, 0.878]</td>\n",
       "      <td>[0.9545, 0.957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_mean</th>\n",
       "      <td>0.815468</td>\n",
       "      <td>0.799482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_sd</th>\n",
       "      <td>0.0812172</td>\n",
       "      <td>0.0697766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_ci_95%</th>\n",
       "      <td>[0.7961, 0.8348]</td>\n",
       "      <td>[0.7828, 0.8161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_ci_99%</th>\n",
       "      <td>[0.7876, 0.8433]</td>\n",
       "      <td>[0.7756, 0.8234]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_mean</th>\n",
       "      <td>0.933102</td>\n",
       "      <td>0.97627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_sd</th>\n",
       "      <td>0.00409865</td>\n",
       "      <td>0.00198093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_ci_95%</th>\n",
       "      <td>[0.9321, 0.9341]</td>\n",
       "      <td>[0.9758, 0.9767]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_ci_99%</th>\n",
       "      <td>[0.9317, 0.9345]</td>\n",
       "      <td>[0.9756, 0.9769]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall_mean</th>\n",
       "      <td>0.799796</td>\n",
       "      <td>0.899925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall_sd</th>\n",
       "      <td>0.12961</td>\n",
       "      <td>0.114674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall_ci_95%</th>\n",
       "      <td>[0.7689, 0.8307]</td>\n",
       "      <td>[0.8726, 0.9273]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall_ci_99%</th>\n",
       "      <td>[0.7554, 0.8442]</td>\n",
       "      <td>[0.8606, 0.9392]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall_mean</th>\n",
       "      <td>0.931934</td>\n",
       "      <td>0.998623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall_sd</th>\n",
       "      <td>0.0066046</td>\n",
       "      <td>0.000858601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall_ci_95%</th>\n",
       "      <td>[0.9304, 0.9335]</td>\n",
       "      <td>[0.9984, 0.9988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall_ci_99%</th>\n",
       "      <td>[0.9297, 0.9342]</td>\n",
       "      <td>[0.9983, 0.9989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision_mean</th>\n",
       "      <td>0.841104</td>\n",
       "      <td>0.72158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision_sd</th>\n",
       "      <td>0.0300031</td>\n",
       "      <td>0.0404037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision_ci_95%</th>\n",
       "      <td>[0.8339, 0.8483]</td>\n",
       "      <td>[0.7119, 0.7312]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision_ci_99%</th>\n",
       "      <td>[0.8308, 0.8514]</td>\n",
       "      <td>[0.7077, 0.7354]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision_mean</th>\n",
       "      <td>0.934293</td>\n",
       "      <td>0.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision_sd</th>\n",
       "      <td>0.00278099</td>\n",
       "      <td>0.00329865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision_ci_95%</th>\n",
       "      <td>[0.9336, 0.935]</td>\n",
       "      <td>[0.9541, 0.9557]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision_ci_99%</th>\n",
       "      <td>[0.9333, 0.9352]</td>\n",
       "      <td>[0.9538, 0.956]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       LogisticRegression     MultinomialNB\n",
       "computation_total               0.0542715         0.0378113\n",
       "test_auc_mean                    0.835612          0.801748\n",
       "test_auc_sd                     0.0630007         0.0642807\n",
       "test_auc_ci_95%          [0.8206, 0.8506]  [0.7864, 0.8171]\n",
       "test_auc_ci_99%           [0.814, 0.8572]  [0.7797, 0.8238]\n",
       "train_auc_mean                   0.937644          0.978924\n",
       "train_auc_sd                   0.00383383        0.00182915\n",
       "train_auc_ci_95%         [0.9367, 0.9386]  [0.9785, 0.9794]\n",
       "train_auc_ci_99%          [0.9363, 0.939]  [0.9783, 0.9796]\n",
       "test_mcc_mean                    0.677811          0.613374\n",
       "test_mcc_sd                      0.115897           0.13499\n",
       "test_mcc_ci_95%          [0.6502, 0.7054]  [0.5812, 0.6456]\n",
       "test_mcc_ci_99%          [0.6381, 0.7175]  [0.5671, 0.6596]\n",
       "train_mcc_mean                   0.875453          0.955752\n",
       "train_mcc_sd                   0.00737948        0.00372086\n",
       "train_mcc_ci_95%         [0.8737, 0.8772]  [0.9549, 0.9566]\n",
       "train_mcc_ci_99%          [0.8729, 0.878]   [0.9545, 0.957]\n",
       "test_f1_mean                     0.815468          0.799482\n",
       "test_f1_sd                      0.0812172         0.0697766\n",
       "test_f1_ci_95%           [0.7961, 0.8348]  [0.7828, 0.8161]\n",
       "test_f1_ci_99%           [0.7876, 0.8433]  [0.7756, 0.8234]\n",
       "train_f1_mean                    0.933102           0.97627\n",
       "train_f1_sd                    0.00409865        0.00198093\n",
       "train_f1_ci_95%          [0.9321, 0.9341]  [0.9758, 0.9767]\n",
       "train_f1_ci_99%          [0.9317, 0.9345]  [0.9756, 0.9769]\n",
       "test_recall_mean                 0.799796          0.899925\n",
       "test_recall_sd                    0.12961          0.114674\n",
       "test_recall_ci_95%       [0.7689, 0.8307]  [0.8726, 0.9273]\n",
       "test_recall_ci_99%       [0.7554, 0.8442]  [0.8606, 0.9392]\n",
       "train_recall_mean                0.931934          0.998623\n",
       "train_recall_sd                 0.0066046       0.000858601\n",
       "train_recall_ci_95%      [0.9304, 0.9335]  [0.9984, 0.9988]\n",
       "train_recall_ci_99%      [0.9297, 0.9342]  [0.9983, 0.9989]\n",
       "test_precision_mean              0.841104           0.72158\n",
       "test_precision_sd               0.0300031         0.0404037\n",
       "test_precision_ci_95%    [0.8339, 0.8483]  [0.7119, 0.7312]\n",
       "test_precision_ci_99%    [0.8308, 0.8514]  [0.7077, 0.7354]\n",
       "train_precision_mean             0.934293            0.9549\n",
       "train_precision_sd             0.00278099        0.00329865\n",
       "train_precision_ci_95%    [0.9336, 0.935]  [0.9541, 0.9557]\n",
       "train_precision_ci_99%   [0.9333, 0.9352]   [0.9538, 0.956]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Logistic model on held-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(data=X_test, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Logistic Regression su test set: 0.7426470588235294\n",
      "AUC Logistic Regression su test set: 0.8197509157509157\n",
      "MCC Logistic Regression su test set: 0.6150105906714609\n",
      "Precision Logistic Regression su test set: 0.6870748299319728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, matthews_corrcoef\n",
    "\n",
    "lr = model['LogisticRegression']\n",
    "y_predicted = lr.predict(test)\n",
    "\n",
    "print(\"F1 Logistic Regression on test set:\", f1_score(y_test, y_predicted))\n",
    "print(\"AUC Logistic Regression on test set:\", roc_auc_score(y_test, y_predicted))\n",
    "print(\"MCC Logistic Regression on test set:\", matthews_corrcoef(y_test, y_predicted))\n",
    "print(\"Precision Logistic Regression on test set:\", precision_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the confidence of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, using this simple approach and a Logistic Regression model, we are able to obtain a good result (0.74 of f1 score). Now it's time to understand if the behavior of the model is correct. For do this, we can analyze the confidence of the model (calculated as the difference of the probabilities for each of the two class) and the features importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = lr.predict_proba(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_score = prob[:,1] - prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train_augmented.copy()\n",
    "df['score'] = confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a37cb16d8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(confidence_score, kde=False, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution plot above, it's clear that the model are not much \"confident\" to assing the label 1 (travel, suggest the item). We have a lot of examples in a zone of uncertainty. If we analyze the distribution in the validation set (that are more unbalanced) we observe that the uncertainty of our model is high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = lr.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_score = prob[:,1] - prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_test.copy()\n",
    "df['score'] = confidence_score\n",
    "df['label_predicted'] = y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a37758390>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(confidence_score, kde=False, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features importance show us that the model takes as important features some reasonable words and others that probabily come from some bias inside the data used for the training (for example \"disney\" or \"japan\"). So, starting from this Logistic regression model, we want to improve the strength of our algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'bottom': [(-0.7362261004274654, 'party'),\n",
       "   (-0.7413033131001128, 'okay'),\n",
       "   (-0.7466894511714356, 'could'),\n",
       "   (-0.7765496522319587, 'safe'),\n",
       "   (-0.7971402549667075, 'literally'),\n",
       "   (-0.7999117812356316, 'someone'),\n",
       "   (-0.805524624118541, 'eat'),\n",
       "   (-0.8210619103066288, 'president'),\n",
       "   (-0.8261008891650106, 'game'),\n",
       "   (-0.8377570140314986, 'smile'),\n",
       "   (-0.8538097197224855, 'amp'),\n",
       "   (-0.8686134335368486, 'run'),\n",
       "   (-0.8790230767614244, 'group'),\n",
       "   (-0.8805683790151752, 'show'),\n",
       "   (-0.8842649489147846, 'people'),\n",
       "   (-0.9727614475107754, 'trump'),\n",
       "   (-0.9783424966100328, 'kid'),\n",
       "   (-1.0062252313696267, 'help'),\n",
       "   (-1.0159630023461117, 'read'),\n",
       "   (-1.246413228665031, 'way')],\n",
       "  'tops': [(1.3488328281834518, 'need'),\n",
       "   (1.3667854544867504, 'love'),\n",
       "   (1.3683216650425765, 'flight'),\n",
       "   (1.417700065269185, 'disney'),\n",
       "   (1.4671663809326094, 'thank'),\n",
       "   (1.4857021969119637, 'planning'),\n",
       "   (1.5034427945671383, 'visit'),\n",
       "   (1.532111177627194, 'plane'),\n",
       "   (1.5412875247088196, 'next'),\n",
       "   (1.6129987440791098, 'airport'),\n",
       "   (1.6262034480841479, 'tomorrow'),\n",
       "   (1.6563843415199733, 'japan'),\n",
       "   (1.6803821586044227, 'place'),\n",
       "   (1.7879125354913052, 'city'),\n",
       "   (1.814725084046841, 'want'),\n",
       "   (1.9631990961181416, 'year'),\n",
       "   (2.7574065769008307, 'plan'),\n",
       "   (3.9299446801416473, 'go'),\n",
       "   (6.316271130134115, 'travel'),\n",
       "   (6.769340999596881, 'trip')]}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = get_most_important_features(vectorizer, lr, n=20)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply any supervised learning algorithm we need more data to build a robust model. To solve these type of problems, we define a different type of learning known as semi-supervised learning, which is used both labelled data (supervised learning) and unlabelled data (unsupervised learning). In pseudo-labelling, instead of manually labeling the unlabelled data, we give approximate labels on the basis of the labelled data. Adding unlabelled data, the decision boundary of our model has become more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pseudo_labelling.png\" height=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the computational cost of the lemmatization step, we have previously extract a sample of 80k examples (for 40k the lemmatization take about 8 hours on MacBook Pro with Intel i9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data_1 = pd.read_csv('data/unlabeled_lemma_40k.csv', index_col=0)\n",
    "unlabeled_data_2 = pd.read_csv('data/unlabeled_lemma_40k_2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = pd.concat([unlabeled_data_1, unlabeled_data_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix  = vectorizer.transform(unlabeled_data[\"lemma\"].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = lr.predict_proba(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data['confidence_score'] = prob[:,1] - prob[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a new sample for training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the noise inside the training set, we sample only the examples that have a confidence score greater than 0.5 (in this way we are sure to increase the precision of our model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_sample = unlabeled_data[unlabeled_data['confidence_score'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2723, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16161</th>\n",
       "      <td>105197</td>\n",
       "      <td>i d love to make that trip again</td>\n",
       "      <td>['love', 'make', 'trip']</td>\n",
       "      <td>['love', 'make', 'trip']</td>\n",
       "      <td>0.910023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>14864</td>\n",
       "      <td>i just realized i m gonna be traveling to new ...</td>\n",
       "      <td>['realized', 'gonna', 'traveling', 'new', 'pla...</td>\n",
       "      <td>['realize', 'go', 'to', 'travel', 'new', 'plac...</td>\n",
       "      <td>0.858341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>89145</td>\n",
       "      <td>foolish heroes  my true plan is for the next w...</td>\n",
       "      <td>['foolish', 'heroes', 'true', 'plan', 'next', ...</td>\n",
       "      <td>['foolish', 'hero', 'true', 'plan', 'next', 'w...</td>\n",
       "      <td>0.662962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15531</th>\n",
       "      <td>38623</td>\n",
       "      <td>makes sense  i m in denver international twic...</td>\n",
       "      <td>['makes', 'sense', 'denver', 'international', ...</td>\n",
       "      <td>['make', 'sense', 'denver', 'international', '...</td>\n",
       "      <td>0.670047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35240</th>\n",
       "      <td>63770</td>\n",
       "      <td>went on a road trip with a friend who is...</td>\n",
       "      <td>['went', 'road', 'trip', 'friend', 'white', 'm...</td>\n",
       "      <td>['go', 'road', 'trip', 'friend', 'white', 'mal...</td>\n",
       "      <td>0.627472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               text  \\\n",
       "16161  105197                   i d love to make that trip again   \n",
       "5148    14864  i just realized i m gonna be traveling to new ...   \n",
       "3276    89145  foolish heroes  my true plan is for the next w...   \n",
       "15531   38623   makes sense  i m in denver international twic...   \n",
       "35240   63770        went on a road trip with a friend who is...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "16161                           ['love', 'make', 'trip']   \n",
       "5148   ['realized', 'gonna', 'traveling', 'new', 'pla...   \n",
       "3276   ['foolish', 'heroes', 'true', 'plan', 'next', ...   \n",
       "15531  ['makes', 'sense', 'denver', 'international', ...   \n",
       "35240  ['went', 'road', 'trip', 'friend', 'white', 'm...   \n",
       "\n",
       "                                                   lemma  confidence_score  \n",
       "16161                           ['love', 'make', 'trip']          0.910023  \n",
       "5148   ['realize', 'go', 'to', 'travel', 'new', 'plac...          0.858341  \n",
       "3276   ['foolish', 'hero', 'true', 'plan', 'next', 'w...          0.662962  \n",
       "15531  ['make', 'sense', 'denver', 'international', '...          0.670047  \n",
       "35240  ['go', 'road', 'trip', 'friend', 'white', 'mal...          0.627472  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' makes sense  i m in denver international twice a year and i never seem to have the time to make sure i see them  but i had some time to spare this trip  i only found two  hoping to see the third next time '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_sample['text'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_sample = unlabeled_data[unlabeled_data['confidence_score'] < -0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a new model using the new labelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reduce again the noise inside the data, we can apply some heuristic rules: for example is possible that one of the most predictive features, the word \"trip\", can be associated to the consuming of drugs. We want to remove this row from our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = r\"\\b(acid trip|drug trip|mental trip|no money)\"\n",
    "\n",
    "def find_false_positive(tweet_text):\n",
    "    return True if re.search(rules, tweet_text) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_sample['to_drop'] = travel_sample['text'].apply(find_false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_sample[travel_sample['to_drop']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>to_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15542</th>\n",
       "      <td>60508</td>\n",
       "      <td>like last week  pretty sure this was not an ac...</td>\n",
       "      <td>['like', 'last', 'week', 'pretty', 'sure', 'ac...</td>\n",
       "      <td>['like', 'last', 'week', 'pretty', 'sure', 'ac...</td>\n",
       "      <td>0.567234</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>38700</td>\n",
       "      <td>i love to go  but i have no money to travel ...</td>\n",
       "      <td>['love', 'money', 'travel', 'far']</td>\n",
       "      <td>['love', 'money', 'travel', 'far']</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>52552</td>\n",
       "      <td>i ve had an acid trip like that</td>\n",
       "      <td>['acid', 'trip', 'like']</td>\n",
       "      <td>['acid', 'trip', 'like']</td>\n",
       "      <td>0.926982</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>58784</td>\n",
       "      <td>it s like a mini acid trip for a sec there</td>\n",
       "      <td>['like', 'mini', 'acid', 'trip', 'sec']</td>\n",
       "      <td>['like', 'mini', 'acid', 'trip', 'sec']</td>\n",
       "      <td>0.521310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>54995</td>\n",
       "      <td>i will and in the meantime it s like i m on a...</td>\n",
       "      <td>['meantime', 'like', 'acid', 'trip', 'somethin...</td>\n",
       "      <td>['meantime', 'like', 'acid', 'trip', 'somethin...</td>\n",
       "      <td>0.541764</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  \\\n",
       "15542  60508  like last week  pretty sure this was not an ac...   \n",
       "13162  38700    i love to go  but i have no money to travel ...   \n",
       "1763   52552                    i ve had an acid trip like that   \n",
       "7850   58784        it s like a mini acid trip for a sec there    \n",
       "37261  54995   i will and in the meantime it s like i m on a...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "15542  ['like', 'last', 'week', 'pretty', 'sure', 'ac...   \n",
       "13162                 ['love', 'money', 'travel', 'far']   \n",
       "1763                            ['acid', 'trip', 'like']   \n",
       "7850             ['like', 'mini', 'acid', 'trip', 'sec']   \n",
       "37261  ['meantime', 'like', 'acid', 'trip', 'somethin...   \n",
       "\n",
       "                                                   lemma  confidence_score  \\\n",
       "15542  ['like', 'last', 'week', 'pretty', 'sure', 'ac...          0.567234   \n",
       "13162                 ['love', 'money', 'travel', 'far']          0.620155   \n",
       "1763                            ['acid', 'trip', 'like']          0.926982   \n",
       "7850             ['like', 'mini', 'acid', 'trip', 'sec']          0.521310   \n",
       "37261  ['meantime', 'like', 'acid', 'trip', 'somethin...          0.541764   \n",
       "\n",
       "       to_drop  \n",
       "15542     True  \n",
       "13162     True  \n",
       "1763      True  \n",
       "7850      True  \n",
       "37261     True  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_sample[travel_sample['to_drop']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_sample = travel_sample[travel_sample['to_drop'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 4\n",
    "\n",
    "def find_short_tweets(tweet_text):\n",
    "    return True if len(tweet_text.split(\" \"))<= max_len else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_sample['too_short'] = travel_sample['text'].apply(find_false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_sample[travel_sample['too_short']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_travel = travel_sample[['index', 'text', 'tokens', 'lemma']]\n",
    "df_travel['label'] = 'travel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general = general_sample[['index', 'text', 'tokens', 'lemma']]\n",
    "df_general['label'] = 'general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudolabel_training = pd.concat([df_general.sample(n=3000, random_state=123), df_travel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = X_train_augmented.sample(n=400, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGrCAYAAABuR4tAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFzdJREFUeJzt3X2wbXV93/EPcPUQKz4WtTEa4kO+PTWOCTcRQoiiaB1Dp6YaE82oVeOoGVKx1kIGNaCTtPEBEvH5iVI7mphIaOIkKE2jiEZkciITjcevCgLW+ABGFJ+OArd/7E09MJfLMWWv377u1+sf9lp7nb2/d8a95u1aa+91wJ49ewIAwDgHjh4AAGDVCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACD7Ro9wPfr4osv3rO2tjZ6DACAW/TNb37zqt27dx96S9vtd0G2traW9fX10WMAANyijY2Ny3eynVOWAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAAPsuXZr9Aiwkpb1s7dr9AAAq+iAXWu54iUPHD0GrJx7/9ZHR4+wV46QAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMtpBf6q+q2yQ5M8lhSdaS/HaSjyc5K8meJB9Lcnx3X19VpyQ5Lsm1SZ7b3RctYiYAgGW1qCNkT0ry5e7++SSPTvLqJKcneeF83QFJHlNVhyd5aJIjkjwhyWsWNA8AwNJaVJD9cZIXbVu+NsnuJOfPl89N8ogkRyc5r7v3dPcVSXZV1aELmgkAYCkt5JRld389SarqkCTvTPLCJK/o7j3zTa5Jcsckd0jy5W1/esP6K2/utbe2trK5ubmIsQEms76+PnoEWFnL2BELCbIkqap7JTknyWu7++1V9bJtTx+S5OokX5s/vun6m7W2tmZHBgD8k03ZERsbGzvabiGnLKvq7knOS3JSd585X/2Rqjpm/vjRSS5I8sEkj6qqA6vq3kkO7O6rFjETAMCyWtQRspOT3DnJi6rqhmvJTkhyRlXdNslmknd293VVdUGSD2UWh8cvaB4AgKW1qGvITsgswG7qoXvZ9tQkpy5iDgCA/YEfhgUAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQ3YKt7143egRYST57wCpZ1L0sf2Cs3eag7P7Pbx09BqycjZc/ZfQIAJNxhAwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYLBdi3rhqjoiyUu7+5iq+sMk95g/dViSC7v7CVX1Z0numuS7Sb7V3Y9e1DwAAMtqIUFWVScmeXKSbyRJdz9hvv7OSd6b5D/ON71fkgd0955FzAEAsD9Y1CnLS5I8di/rX5zkVd39+aq6e5I7JXlXVX2gqv7NgmYBAFhqCzlC1t1nV9Vh29dV1d2SHJvvHR27bZLTkrwyyV2SfLCqLuruL+3rtbe2trK5uXnrD30z1tfXJ3sv4Mam/KxPzb4FxlnGfcvCriHbi19K8vbuvm6+/IUkr+/ua5N8qao+kqSS7DPI1tbW7MhgRfisA4sw5b5lY2NjR9tN+S3LRyQ59ybLf5QkVXX7JD+RZPmSFQBgwaYMskpy6Q0L3X1ukk9V1YVJzktycndfNeE8AABLYWGnLLv7siRHblt+wF62ee6i3h8AYH/hh2EBAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBdi3qhavqiCQv7e5jqurwJO9K8qn506/r7ndU1SlJjktybZLndvdFi5oHAGBZLSTIqurEJE9O8o35qsOTnN7dp23b5vAkD01yRJJ7JTk7yc8sYh4AgGW2qFOWlyR57Lbl3UmOq6r3V9VbquqQJEcnOa+793T3FUl2VdWhC5oHAGBpLeQIWXefXVWHbVt1UZI3d/dGVb0gySlJrk7y5W3bXJPkjkmu3Ndrb21tZXNz81ae+Oatr69P9l7AjU35WZ+afQuMs4z7loVdQ3YT53T31Tc8TvKqJH+a5JBt2xySWaTt09ramh0ZrAifdWARpty3bGxs7Gi7qb5l+Z6qevD88bFJNpJ8MMmjqurAqrp3kgO7+6qJ5gEAWBpTHSH79SSvrqrvJPlCkmd299eq6oIkH8osDI+faBYAgKWysCDr7suSHDl//LdJjtrLNqcmOXVRMwAA7A/8MCwAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGGzXol64qo5I8tLuPqaqfjLJq5Jcl2QryVO6+4tVdUaSn0tyzfzPHtPdX13UTAAAy2ghQVZVJyZ5cpJvzFe9Msl/6O6Lq+pZSU5K8rwkhyd5VHdftYg5AAD2B4s6ZXlJksduW35Cd188f7wryber6sAk90/yxqr6YFU9fUGzAAAstYUcIevus6vqsG3Ln0+SqjoqyW8keUiSf5bZaczTkxyU5L1V9Tfd/Xf7eu2tra1sbm4uYuy9Wl9fn+y9gBub8rM+NfsWGGcZ9y0Lu4bspqrqV5K8IMlx3X1lVR2U5JXd/c3583+V5EFJ9hlka2trdmSwInzWgUWYct+ysbGxo+0mCbKqelKSZyU5prv/cb76x5P8YVUdntmp06OT/Pcp5gEAWCYLD7L5kbAzklyR5E+qKknO7+5TquptSS5M8t0kb+3uv1/0PAAAy2ZhQdbdlyU5cr54l5vZ5mVJXraoGQAA9gd+GBYAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADLajIKuqZ9xk+TmLGQcAYPXs2teTVfXEJP82ycOq6uHz1Qcl+YkkZyx4NgCAlbDPIEvy7iSfT3LXJG+Yr7s+ySWLHAoAYJXsM8i6+ytJ3pfkfVV1tyQH7+TvAADYuR2FVVW9JslxSf4hyQFJ9iQ5aoFzAQCsjJ0e6ToiyX26+/pFDgMAsIp2+rMXn873TlcCAHAr2ukRsnsnubyqPj1f3tPdTlkCANwKdhpkT1zoFAAAK2ynQfbv97LuJbfmIAAAq2qnQfbF+X8PSHJ43HIJAOBWs6Mg6+43bF+uqnMXMw4AwOrZ6e+Q/fi2xX+R2UX+AADcCnZ6ynL7EbJvJ3n+AmYBAFhJOz1l+bCqumuS+ya5tLuvWuxYAACrY0cX51fV45P8dZKTk1xYVU9a6FQAACtkp9+WfF6S3d39i0l+KskJixsJAGC17DTIru/urydJd1+T2XVkAADcCnZ6Uf8lVXVakvcn+fkklyxuJACA1bLTI2RvTPKPSR6Z5GlJXr2wiQAAVsxOg+z0JOd0928k+Zn5MgAAt4KdBtm13f3xJOnuS5Ncv7iRAABWy06vIbu8qv5Lkg8leXCSzy1uJACA1bLTIHtakmcn+YUkm0l++5b+oKqOSPLS7j6mqu6X5Kwke5J8LMnx3X19VZ2S5Lgk1yZ5bndf9P3/EwAA9m87/aX+byf5/Z2+aFWdmOTJSb4xX3V6khd29/uq6vVJHlNVlyd5aJIjktwrydmZXZ8GALBSdnoN2ffrkiSP3ba8O8n588fnJnlEkqOTnNfde7r7iiS7qurQBc0DALC0FhJk3X12ku9uW3VAd++ZP74myR2T3CHJV7dtc8N6AICVstNryP5/bf9W5iFJrk7ytfnjm67fp62trWxubt660+3D+vr6ZO8F3NiUn/Wp2bfAOMu4b5kqyD5SVcd09/uSPDrJe5N8OsnLquoVSX4kyYHdfdUtvdDa2podGawIn3VgEabct2xsbOxou6mC7D8leVNV3Tazb2m+s7uvq6oLMvspjQOTHD/RLAAAS2VhQdbdlyU5cv74k5l9o/Km25ya5NRFzQAAsD9Y1LcsAQDYIUEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMtmuqN6qqpyZ56nzx4CQ/meRXk7w8yWfn60/p7vOnmgkAYBlMFmTdfVaSs5Kkql6T5Mwkhyc5sbvPnmoOAIBlM/kpy6r66SQP6O43Jtmd5OlVdUFVnVZVkwUiAMCyGBFAJyd58fzx/0ryP5N8Jsnrkzw7yav39cdbW1vZ3Nxc6IDbra+vT/ZewI1N+Vmfmn0LjLOM+5ZJg6yq7pTkX3b3e+erzuzuq+fP/WmSx93Sa6ytrdmRwYrwWQcWYcp9y8bGxo62m/qU5UOS/GWSVNUBSf6uqn5k/tyxSXY2NQDAD5Cpg6ySXJok3b0nyTOS/ElVnZ/kdkneNPE8AADDTXrKsrtffpPl85KcN+UMAADLxg/DAgAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBdk35ZlX1kSRfnS9+JskbkrwyybVJzuvuF085DwDAMpgsyKrq4CTp7mO2rbs4yeOSXJrkz6vq8O7+26lmAgBYBlMeIXtQkttV1Xnz9z01yVp3X5IkVfWeJMcmEWQAwEqZMsi+meQVSd6c5P5Jzk1y9bbnr0lyn1t6ka2trWxubi5kwL1ZX1+f7L2AG5vysz41+xYYZxn3LVMG2SeTfLq79yT5ZFV9Ncldtj1/SG4caHu1trZmRwYrwmcdWIQp9y0bGxs72m7Kb1k+PclpSVJVP5zkdkm+UVX3raoDkjwqyQUTzgMAsBSmPEL2liRnVdUHkuzJLNCuT/K2JAdl9i3LD084DwDAUpgsyLr7O0l+dS9PHTnVDAAAy8gPwwIADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIPtmuqNquo2Sc5McliStSS/neT/JHlXkk/NN3tdd79jqpkAAJbBZEGW5ElJvtzdT66quyb5SJKXJDm9u0+bcA4AgKUyZZD9cZJ3blu+NsnuJFVVj8nsKNlzu/uaCWcCABhusiDr7q8nSVUdklmYvTCzU5dv7u6NqnpBklOSPH9fr7O1tZXNzc1Fj/v/rK+vT/ZewI1N+Vmfmn0LjLOM+5Ypj5Clqu6V5Jwkr+3ut1fVnbr76vnT5yR51S29xtramh0ZrAifdWARpty3bGxs7Gi7yb5lWVV3T3JekpO6+8z56vdU1YPnj49NsrOpAQB+gEx5hOzkJHdO8qKqetF83fOS/H5VfSfJF5I8c8J5AACWwpTXkJ2Q5IS9PHXUVDMAACwjPwwLADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAbbNXqAqjowyWuTPCjJVpJndPenx04FADCdZThC9otJDu7un03ym0lOGzwPAMCkliHIjk7y7iTp7guT/PTYcQAApnXAnj17hg5QVW9OcnZ3nztfviLJfbr72r1tv7GxcWWSyyccEQDgn+pHd+/efegtbTT8GrIkX0tyyLblA28uxpJkJ/8oAID9yTKcsvxgkl9Ikqo6MslHx44DADCtZThCdk6SR1bVXyc5IMnTBs8DADCp4deQAQCsumU4ZQkAsNIEGQDAYIKM/UZVHVxVz1jA637h1n5NgJuqqsOq6sLRc7CcBBn7k3skudWDDABGW4ZvWcJOvSDJv6qq65P8ZZLbJ/m1JE/J7A4PhyTZ7O6nVdXfJPml7r6sqh6f2R0hfivJW5Lcdf56z+luP7MCK6aqfijJW5P8cJLPJnlIkkclOSOzb/t/OcnTk/xUkpOSfCfJjyV5R3f/TlXdK8kbkxyc5NtJnpnkoCTvmv/tXyT5cJJT5m95u8z2U9+Z4J/HfsoRMvYnv5Pk40lekll4HZXkc0m+0t2PTHJUkiOr6p6ZhddT5n/31CRvSnJykv/d3Q/LbAf6umnHB5bEM5N8prt/LsmpSe6e2T7i+O4+JrOgOnG+7Y8meVySn9227hVJzpjvS16R5Hfn6++R5F9398uSPCDJk7r74Un+LMnjF/xvYj/nCBn7q57/91tJ7lZVf5Dk65kdNbtNkrcl+cD81lx36O6PVdUDkzy8qn5l/rd3nnpoYCms53v3UP5EVV05X/faqkpm+5BPzrf96PzuMddW1bfm6x6Y5OSqOimzI2o3HPn6THff8PhzSc6oqq8nuWdmP4ION8sRMvYn1+d7/5u9fv7fRye5V3c/MbMjYD+U5IDu/lqSjSS/l+S/zbf9RJLfm/8/4F/OLNqA1fOxzI54parum+SfZ/Z/8p4y3z+cmOTP59vu7cc6P5HkpPm2z0ryzvn667dt8+YkT+vupyb5h8zCDW6WI2TsT76U5LaZRdcNLkryovk3l7aSXJrZdSGfyewUxLszuxYkmZ3yfEtVPTPJHTI7VQGsnrckOauq3p/k8syuA/v1JG+tqoPm2/xaZvuSvXl+ktdV1cGZ7Y9O2Ms2/yPJh6vqK0m+uI/XgiR+qR+AFVNVRyW5fXefV1X3T/Lu7r7v6LlYbY6QAbBqLk3yB1V1SmbXix0/eB5whAwAYDQX9QMADCbIAAAGE2QAAIMJMuAHWlU9tap+92aeO7Wqnr3D19nxtgDfL0EGADCYn70AVkJV/dfc5Cb086f+XVX9cmY3gH5Od180vyH985Jcl+QD3f2bQ4YGVoYjZMAquG32fhP6ZHb/wYdn9svsr6+quyR5cZJju/voJPesqkcOmRpYGY6QAatgT/Z+E/okeX+SdPffV9U9ktwvyaFJ/mJ+o+lDktxn8omBleIIGbAKHpa93IR+/tyDk6SqHpjkiszug/rZJI+c3zz6VUk+PPXAwGpxhAxYBRcl2b2Xm9AnyY9V1V8lWUvyrO6+sqpOT3L+/EbTlyX5owEzAyvErZMAAAZzyhIAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBg/xdYZJ7OEd130QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(data=new_test, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([X_train_augmented[~X_train_augmented['index'].isin(new_test['index'])], X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>11884</td>\n",
       "      <td>why people think prince philip amp     s car c...</td>\n",
       "      <td>['people', 'think', 'prince', 'philip', 'amp',...</td>\n",
       "      <td>['people', 'think', 'prince', 'philip', 'amp',...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36522</th>\n",
       "      <td>42055</td>\n",
       "      <td>agency  orange county sheriff s department cal...</td>\n",
       "      <td>['agency', 'orange', 'county', 'sheriff', 'dep...</td>\n",
       "      <td>['agency', 'orange', 'county', 'sheriff', 'dep...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>4577</td>\n",
       "      <td>lost my husband in car crash  then my job  a...</td>\n",
       "      <td>['lost', 'husband', 'car', 'crash', 'job', 'am...</td>\n",
       "      <td>['lose', 'husband', 'car', 'crash', 'job', 'am...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28752</th>\n",
       "      <td>33109</td>\n",
       "      <td>i     near i    shut down in both directions a...</td>\n",
       "      <td>['near', 'shut', 'directions', 'multi', 'vehic...</td>\n",
       "      <td>['near', 'shut', 'direction', 'multi', 'vehicl...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26960</th>\n",
       "      <td>31059</td>\n",
       "      <td>my goodness  labour s richard burgon has given...</td>\n",
       "      <td>['goodness', 'labour', 'richard', 'burgon', 'g...</td>\n",
       "      <td>['goodness', 'labour', 'richard', 'burgon', 'g...</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  \\\n",
       "10332  11884  why people think prince philip amp     s car c...   \n",
       "36522  42055  agency  orange county sheriff s department cal...   \n",
       "3988    4577    lost my husband in car crash  then my job  a...   \n",
       "28752  33109  i     near i    shut down in both directions a...   \n",
       "26960  31059  my goodness  labour s richard burgon has given...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "10332  ['people', 'think', 'prince', 'philip', 'amp',...   \n",
       "36522  ['agency', 'orange', 'county', 'sheriff', 'dep...   \n",
       "3988   ['lost', 'husband', 'car', 'crash', 'job', 'am...   \n",
       "28752  ['near', 'shut', 'directions', 'multi', 'vehic...   \n",
       "26960  ['goodness', 'labour', 'richard', 'burgon', 'g...   \n",
       "\n",
       "                                                   lemma    label  \n",
       "10332  ['people', 'think', 'prince', 'philip', 'amp',...  general  \n",
       "36522  ['agency', 'orange', 'county', 'sheriff', 'dep...  general  \n",
       "3988   ['lose', 'husband', 'car', 'crash', 'job', 'am...  general  \n",
       "28752  ['near', 'shut', 'direction', 'multi', 'vehicl...  general  \n",
       "26960  ['goodness', 'labour', 'richard', 'burgon', 'g...  general  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabel_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([training, pseudolabel_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7585, 5)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(data=all_data, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate different Features set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this final task, we want to analyze different feature set in addition to the BoW representation after the lemmatization step. We consider a binary representation of the tokens extracted (including the stopwords) and the skip gram matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessing(lemmatization = False, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning...\n",
      "Standardization...\n",
      "Tokenization...\n",
      "Finish\n",
      "CPU times: user 153 ms, sys: 3.55 ms, total: 156 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%time all_data = tp.fit(all_data, \"text\", min_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from nltk.util import skipgrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipper = functools.partial(skipgrams, n=2, k=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_toVect = VectorizeData(method='binary')\n",
    "train_gram, vectorizer_gram = token_toVect.fit(all_data[\"tokens\"], skipper=skipper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_toVect = VectorizeData(method='tf-idf')\n",
    "train_tokens, vectorizer_tokens = token_toVect.fit(all_data[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lemma, vectorizer_lemma = token_toVect.fit(all_data[\"lemma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7585, 12381) (7585, 14786) (7585, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(train_lemma.shape, train_tokens.shape, train_gram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = { 'lemma': train_lemma,\n",
    "                'tokens': train_tokens,\n",
    "                'gramk2': train_gram\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(all_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidation(models=[\"LogisticRegression\"], \n",
    "                     scores = [\"auc\", \"mcc\", \"f1\", \"recall\", \"precision\"],\n",
    "                     params_file = \"./param_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START WITH: \n",
      "lemma\n",
      "Model: LogisticRegression\n",
      "Searching the best LogisticRegression with grid search cv...\n",
      "\n",
      "Best_estimator: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best_scores: 0.9519744242103475\n",
      "Evaluate the best model configuration with a new cross validation...\n",
      "\n",
      "Finish\n",
      "START WITH: \n",
      "tokens\n",
      "Model: LogisticRegression\n",
      "Searching the best LogisticRegression with grid search cv...\n",
      "\n",
      "Best_estimator: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best_scores: 0.9509264347296913\n",
      "Evaluate the best model configuration with a new cross validation...\n",
      "\n",
      "Finish\n",
      "START WITH: \n",
      "gramk2\n",
      "Model: LogisticRegression\n",
      "Searching the best LogisticRegression with grid search cv...\n",
      "\n",
      "Best_estimator: LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=False,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best_scores: 0.9247622526295455\n",
      "Evaluate the best model configuration with a new cross validation...\n",
      "\n",
      "Finish\n",
      "CPU times: user 10.5 s, sys: 506 ms, total: 11 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for key, value in feature_set.items():\n",
    "    print(\"START WITH: \\n{}\".format(key))\n",
    "    res, model = cv.fit_cv(value, y_train)\n",
    "    models_dict[key] = model\n",
    "    res.to_csv('results/{}.csv'.format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and final evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = lb.fit_transform(new_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test  = vectorizer_lemma.transform(new_test[\"lemma\"].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Logistic Regression on test set: 0.7979539641943735\n",
      "AUC Logistic Regression on test set: 0.8028846153846154\n",
      "MCC Logistic Regression on test set: 0.6052919875803631\n",
      "Precision Logistic Regression on test set: 0.7839195979899497\n"
     ]
    }
   ],
   "source": [
    "lr = models_dict['lemma']['LogisticRegression']\n",
    "y_predicted = lr.predict(x_test)\n",
    "\n",
    "print(\"F1 Logistic Regression on test set:\", f1_score(y_test, y_predicted))\n",
    "print(\"AUC Logistic Regression on test set:\", roc_auc_score(y_test, y_predicted))\n",
    "print(\"MCC Logistic Regression on test set:\", matthews_corrcoef(y_test, y_predicted))\n",
    "print(\"Precision Logistic Regression on test set:\", precision_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the model fitted on the original training set with the pseudo-labeled set, we can see that we have an improvement of about 10% in our scores. Also, the confidence of our model seems better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = lr.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_score = prob[:,1] - prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_test.copy()\n",
    "df['score'] = confidence_score\n",
    "df['label_predicted'] = y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAFoCAYAAACc1hUlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFrdJREFUeJzt3X2QXeddH/Dv2mutrUiRX+REOziGcWM/0ZQBHLUQit86NQSXZFwo7XRIGUiAUPAMb+kQQgwMbWZSCDUNpUDjxHUyNB2IiVtgcNJpSewkkHqyKAymy2PiDm5UVmnkyO6StVa70vaPe7fZytp7rx7tudq7+nxmNHPvOeee5zm/fe65X51zz7lTa2trAQDg3F1yoTsAADCpBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGglSAACNBCkAgEbT42jk05/+9NrMzMym85eXlzNo/sVCHdRgnTr0qIMarFMHNVg3jjosLS0dO3To0LWjLDuWIDUzM5ODBw9uOn9+fn7g/IuFOqjBOnXoUQc1WKcOarBuHHWYm5t7etRlndoDAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANBKkAAAaCVIAAI0EKQCARtMXugOT5rmlk1lcXu1k3Sen9+TI8aXsnZnOvt27OmkDANg6gtQ5WlxezWNPHutk3QtHFzJ7YC233bRfkAKACeDUHgBAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGglSAACNBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGglSAACNBCkAgEbToyxUSnlJkrkk35hkNcmDSdaSPJHknlrr6a46CACwXQ09IlVKuSzJv03yfH/SfUnurbXemmQqyd3ddQ8AYPsa5dTeLyT5tSR/2X9+KMmj/cePJLmzg34BAGx7A4NUKeW7k3y+1vrhDZOnaq1r/ceLSfZ11DcAgG1t2Hek3pBkrZRyZ5KvSfK+JC/ZMH9vkmeHNbK8vJz5+flN5584cWLg/O3k5PSeLBxd6GTdqysrWTi6kGeunsri0ac7aWO7m6Sx0CV16FEHNVinDmqwbrvVYWCQqrXetv64lPLRJP8kyTtKKXfUWj+a5K4kHxnWyMzMTA4ePLjp/Pn5+YHzt5Mjx5cye2Bt+IINFo4uZPbAbK7Zf02uu+plnbSx3U3SWOiSOvSogxqsUwc1WDeOOszNzY287EhX7Z3hTUnuL6XsSjKf5KGGdQAATLyRg1St9Y4NT2/f+q4AAEwWN+QEAGgkSAEANBKkAAAatXzZnI6tnjqdI8eXOm9n78x09u3e1Xk7ALBTCVLb0PMrp3P4qS903s5tN+0XpADgPDi1BwDQSJACAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANJq+0B0AAHaG55ZOZnF5tdM2Lpl5UafrP1eCFACwJRaXV/PYk8c6beOvXz3V6frPlVN7AACNBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGglSAACNBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGglSAACNBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGglSAACNBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADSaHrZAKeXSJPcnKUlOJXl9kqkkDyZZS/JEkntqrae76yYAwPYzyhGp1yZJrfUbkvx0kvv6/+6ttd6aXqi6u7MeAgBsU0ODVK31PyZ5Y//plyf5XJJDSR7tT3skyZ2d9A4AYBsbemovSWqtq6WU9yb51iTfnuQ1tda1/uzFJPsGvX55eTnz8/Obzj9x4sTA+dvJyek9WTi60Mm6V1dWsnB0Ia/Yv6uzNjZ65uqpLB59uvN2zsUkjYUuqUOPOqjBOnWYjBp0+Rm5rrz42m1Vh5GCVJLUWr+rlPLmJP8tyRUbZu1N8uyg187MzOTgwYObzp+fnx84fzs5cnwpswfWhi/YYOHoQmYPzOaK3bsze2C2kzY2umb/Nbnuqpd13s65mKSx0CV16FEHNVinDpNRgy4/I9dNT0/l4I03dNrG3NzcyMsOPbVXSvnOUspb+k+XkpxO8qlSyh39aXcl+dg59hEAYOKNckTqg0n+XSnlsSSXJfmRJPNJ7i+l7Oo/fqi7LgIAbE9Dg1St9YtJ/uFZZt2+9d0BAJgcbsgJANBIkAIAaDTyVXsAwGR6bulkFpdXO29neeVU521sN4IUAOxwi8ureezJY523c/P1V3bexnbj1B4AQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQKPpC90BLpzVU6dz5PhSp23snZnOvt27Om0DAC4UQeoi9vzK6Rx+6gudtnHbTfsFKQB2LKf2AAAaCVIAAI0EKQCARoIUAEAjQQoAoNGOumrvuaWTWVxe7bSN5ZVTna4fAJgcOypILS6v5rEnj3Xaxs3XX9np+gGAyeHUHgBAI0EKAKDRwFN7pZTLkjyQ5CuSzCR5W5L/nuTBJGtJnkhyT631dKe9BADYhoYdkfrHSZ6ptd6a5K4kv5zkviT39qdNJbm72y4CAGxPw4LUB5L81Ibnq0kOJXm0//yRJHd20C8AgG1v4Km9WutfJUkpZW+Sh5Lcm+QXaq1r/UUWk+wb1sjy8nLm5+c3nX/ixImB80d1cnpPFo4unPd6BnnF/l2dtbG6spKFowudtrHRONp55uqpLB59euTlt2osTDp16FEHNVh3oepwycyLcuLUVKdtXH7pWk4vf3HocudTg3F8Pibj+VwpL752W70nht7+oJTysiQPJ/mVWuv7Syk/v2H23iTPDlvHzMxMDh48uOn8+fn5gfNHdeT4UmYPrA1f8DxcsXt3Zg/MdrLuhaMLmT0w22kbG42jnWv2X5PrrnrZyMtv1ViYdOrQow5qsO5C1eHI8aXMdXxbndtu2p/rrrp+6HLnU4NxfD4m4/lcmZ6eysEbb+i0jbm5uZGXHXhqr5Ty0iT/Ocmba60P9CcfLqXc0X98V5KPNfQRAGDiDTsi9ZNJrkryU6WU9e9K/XCSXyql7Eoyn94pPwCAi86w70j9cHrB6Uy3d9MdAIDJ4YacAACNBCkAgEaCFABAo6G3PwDYrp5bOpnF5dXO29k7M519u3d13g6jG9fffnnlVOdtMNkEKWBiLS6v5rGO7/GT9O7zI0htL+P62998/ZWdt8Fkc2oPAKCRIAUA0EiQAgBoJEgBADQSpAAAGrlqDy5C47h03C0DYDSrp07nyPGlocudnN4z0nJn4zYO3RGk4CI0jkvH3TIARvP8yukcfuoLQ5dbOLqQ2QNrTW24jUN3nNoDAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANBKkAAAaTV/oDsBWeG7pZBaXVzttY+/MdPbt3tVpG+vbcXJ6T44cX+qsneWVU52tG7p4P575njCG2S4EKXaExeXVPPbksU7buO2m/Z0HqfXtWDi6kNkDa521c/P1V3a2buji/Xjme8IYZrtwag8AoJEgBQDQSJACAGgkSAEANBKkAAAaCVIAAI3c/gDoxOqp0+d9L6xh99NyL6FzM477rSX+LlxcBCmgE8+vnM7hp75wXusYdj8t9xI6N+O431ri78LFxak9AIBGghQAQCNBCgCgkSAFANBIkAIAaOSqPRjRVlzOP4zLxgEmiyAFI9qKy/mHcdk4wGRxag8AoJEgBQDQSJACAGgkSAEANBKkAAAaCVIAAI0EKQCARoIUAEAjQQoAoJEgBQDQSJACAGgkSAEANPKjxQDbwHNLJ7O4vPqC6Sen9+TI8aUtaWN55dSWrAf4EkEKYBtYXF7NY08ee8H0haMLmT2wtiVt3Hz9lVuyHuBLnNoDAGgkSAEANBrp1F4p5euS/Fyt9Y5SysuTPJhkLckTSe6ptZ7urosAANvT0CNSpZQfT/LuJJf3J92X5N5a661JppLc3V33AAC2r1FO7T2V5Ns2PD+U5NH+40eS3LnVnQIAmARDg1St9beSrGyYNFVrXb+EZDHJvi46BgCw3bXc/mDj96H2Jnl22AuWl5czPz+/6fwTJ04MnD+qk9N7snB04bzXM8gr9u/qrI3VlZUsHF3otI2NxtHOcy+dyTPHnhl5+dXM5I///LPn3M7UpZdN9N/+zDbWx0LX7XRpK9oYVodxvVfOdRy32GwMb+VYmOR9y5l1mORtaW3jfMbCTqpXefG1W5IZtkpLkDpcSrmj1vrRJHcl+ciwF8zMzOTgwYObzp+fnx84f1RHji9t2f1WNnPF7t2ZPTDbybp794uZ7bSNjcbRziUzV+RPP7c88vILRz/f1Kebr+9+W8ZRr/U21sdC1+10aSvaGFaHcb1XznUct9hsDG/lWJjkfcuZdZjkbWlt43zGwk6q1/T0VA7eeEOnbczNzY28bEuQelOS+0spu5LMJ3moYR0AABNvpCBVa/2LJK/qP34yye0d9gkAYCK4IScAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBGghQAQCNBCgCgkSAFANBIkAIAaCRIAQA0EqQAABoJUgAAjQQpAIBG0y0vKqVckuRXknx1kuUk31tr/cxWdgwAYLtrPSL195JcXmv9+iQ/keRfbl2XAAAmQ2uQuiXJh5Kk1vrJJH9jy3oEADAhWoPUi5M8t+H5qVJK02lCAIBJNbW2tnbOLyql3Jfkk7XW3+w/P1JrvW6z5efm5j6f5OnmXgIAjM+XHzp06NpRFmw9ivSJJK9N8pullFcl+ZNBC4/aGQCASdIapB5O8o2llD9IMpXk9VvXJQCAydB0ag8AADfkBABoJkgBADQSpAAAGo393k+llG9N8g9qrd9xlnnfl+T7k6wmeVut9XdLKfuTvD/JFUn+Msnra61L4+zzViqlXJHk15O8JMliku+qtX5+w/xvTu9u8Unvi/y3JPnK9Lb/d5L8eX/er9Zaf2Nc/d5Kw2rQX+a3k1yTZCXJ87XWu0opL0/yYJK1JE8kuafWenqcfd9KI9bhHemNgekk76q13l9KuTrJk+nVIEkerrW+c3w9P3/DfmbqYtgXJCPV4UeT/KP+09+rtf5sKWUqyZF8aV/wh7XWt4yx21tuhDr8UpJvSO99kiR3J7ksO2g8DKpBKeVrkvyrDYu/Kr1fGHk8E74v2Ewp5euS/Fyt9Y4zpr82yU+nt294oL9PHLov7dJYj0iVUt6Z5O1na7eUciDJD6X3Znl1kreXUmbSK9j7a623Jjmc3s51kv1Akj/pb8/7kty7cWat9UO11jv6g+d30xtI80lemeS+9XmTGqL6Btag7+VJbulv6139afclubf/uqn0dqaTbGAdSil/O8nL+z/FdEuSN5dSrkpvLPyHDWNhEnecm/7M1EW0L0gG1+GGJK9L8reSfH2SbyqlfFWSv5bkjzb8/Sc6RPUN+9mxVyZ59YZtfi47bzxsWoNa66c3fC78myQfrLV+KDtjX/ACpZQfT/LuJJefMf2yJL+Y5JuS3J7kjf39xSifKZ0Z96m9P0hvg8/ma5N8ota63H+TfCbJV2XDz9EkeSTJnZ33slsjbU8p5bok35nkZ/uTDiX5llLKY6WU95RS9nbe0+4MrEEp5aVJrkzyO6WUj5dSXtOfdSjJo5u9bgINGwt/mOQN/cdrSS5N7wjdoSSvLKU8Wkr5QClldhyd3WKDfmbqYtkXJIPr8Nkk31xrPdU/8npZkhPp/f2/rJTykVLK75VSyrg73YFN69A/UnNjkneVUj5RSnnDma/JzhgPQ396rZTyovQ+E36oP2kn7AvO5qkk33aW6QeTfKbWerzWejLJx5Pcmgs8Fjo5tVdK+Z4kP3rG5NfXWn+jlHLHJi8782dnFpPsO2P6+rSJsEkdPpfRtufHkvxirXW5//zxJO+utc6VUt6a5GeS/NMt7vKWa6zBrvT+N/bOJFcn+UQp5fEkU7XWtQGv27Za6lBrPZHkRP9/Ye9N79TeX5VS/izJXK31v5RSXpfkXyf59k43YOud9Wemaq2rZ5k38fuCATatQ611Jcmx/qm8dyQ5XGt9sv8/8LfXWj9QSrklvVMaf3P8Xd9Sg8bDi9Ib4/el95+Jj5RSPpWdNx4G1WDd9yT5QK31WP/5TtgXvECt9bdKKV9xllnbct/QSZCqtb4nyXvO8WX/J8nGoyx7kzy7YfrzG6ZNhLPVoZTywXxpO8+6Pf3/gb0myVs3TH641rq+7MPpvWG2vcYaHE3ya/0dyP8upRxOUpJs/D7UxTIWrkryUJKP1lrf3p/8+0nWvwvycJJ/1kWfO3bm+/2SDR8YO25fMMCgOqSUcnmSB9L7cPjB/uRPpff9kNRaP15K+bJSysb/ZEyiQXVYSvLO9e8/lVJ+P73vEe208TBwLPS9Lv9/UNoJ+4JzMWzfsHHa2Gynq/YeT3JrKeXyUsq+9A7hPZHez9H83f4ydyX52AXq31YZZXu+Msmf1Vqf3zDtw6WUr+0//jtJ5rrrYueG1eDOJOu/47gnvXrMJzm84Yjmjh8L/S9Q/tf0vlD5zzfMeneSv99/PKlj4f9t+1l+Zupi2RckA+rQPxL1n5L8ca31+2utp/qzfibJj/SX+eok/3PCQ1QyeDzclOTjpZRL+0dnb0nyR9l542FQDdJ/L8zUWj+7YfJO2Beci/kkN5ZSri6l7EpyW3pfgbigY2HsV+2dqZTyY+md8/zt/pUZH0sv4L211nqilPK2JO/tX8VzLMkLrvabML+a3vZ8PMnJ9LenlPLzSR6qtT6e3tGX/3HG634gyS+XUk6md8TmjePr8pYbVoNHSimvLqV8Mr2jUD9Zaz1WSnlTkvv7b6D59I7UTLKBdUjvy9Y3JPm+/vhPej/H9BNJHiil/GCSLyb53nF3fAu84GemLsJ9QTKgDumdxro9yUwpZf2Ci7ck+RdJfr2U8i3pHZn67rH3eusNGw//Pskn0/uO4PtqrX+6A8fDwBqkFyj/4ozX7IR9wVCllO9IsqfW+q5+TT6c3r7hgVrr/yqlnHVfOi5+IgYAoNF2OrUHADBRBCkAgEaCFABAI0EKAKCRIAUA0EiQAgBoJEgBADQSpAAAGv1fq0p3MjTBBHYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(confidence_score, kde=False, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the most predictive features are better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'bottom': [(-1.2633272479328221, 'school'),\n",
       "   (-1.264364815413947, 'truck'),\n",
       "   (-1.281964904665663, 'game'),\n",
       "   (-1.3025146373400616, 'woman'),\n",
       "   (-1.3283092450986669, 'bad'),\n",
       "   (-1.341768673556547, 'driver'),\n",
       "   (-1.4172654330189658, 'run'),\n",
       "   (-1.4373490317635977, 'trump'),\n",
       "   (-1.4849473454662827, 'kid'),\n",
       "   (-1.4912839979661814, 'show'),\n",
       "   (-1.550973561597181, 'way'),\n",
       "   (-1.5964932308040678, 'say'),\n",
       "   (-1.642219538334741, 'die'),\n",
       "   (-1.8538739291344188, 'people'),\n",
       "   (-1.917537093925974, 'amp'),\n",
       "   (-2.297227887010879, 'hit'),\n",
       "   (-2.425206161276598, 'vehicle'),\n",
       "   (-2.5111520708793957, 'break'),\n",
       "   (-4.47546734486943, 'crash'),\n",
       "   (-5.939859062069736, 'car')],\n",
       "  'tops': [(2.076837051358658, 'month'),\n",
       "   (2.1241817365653644, 'weekend'),\n",
       "   (2.1243683016313306, 'world'),\n",
       "   (2.1277694757142616, 'to'),\n",
       "   (2.1724824249054846, 'day'),\n",
       "   (2.261428729804724, 'thank'),\n",
       "   (2.2990351652562984, 'city'),\n",
       "   (2.347565400425259, 'tomorrow'),\n",
       "   (2.409571583380099, 'need'),\n",
       "   (2.533599431416559, 'time'),\n",
       "   (2.8221601736599933, 'place'),\n",
       "   (2.9025080643781727, 'visit'),\n",
       "   (3.0656140940242436, 'want'),\n",
       "   (3.260211321218834, 'next'),\n",
       "   (3.4128057626413533, 'year'),\n",
       "   (3.638429678712292, 'love'),\n",
       "   (4.80705872679986, 'plan'),\n",
       "   (7.179351043336206, 'go'),\n",
       "   (11.367137100345447, 'travel'),\n",
       "   (13.815160642022835, 'trip')]}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = get_most_important_features(vectorizer_lemma, lr, n=20)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the final model can also be increase by changing the decision threshold. Obviously, if you want to increase the precision you have to reduce the recall. The final configuration can be set using the business knowledge of our specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_prediction(score):\n",
    "    if score > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred = df['score'].apply(my_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Logistic Regression on test set: 0.6645367412140575\n",
      "AUC Logistic Regression on test set: 0.7299679487179486\n",
      "MCC Logistic Regression on test set: 0.5002473562177442\n",
      "Precision Logistic Regression on test set: 0.859504132231405\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Logistic Regression on test set:\", f1_score(y_test, my_pred))\n",
    "print(\"AUC Logistic Regression on test set:\", roc_auc_score(y_test, my_pred))\n",
    "print(\"MCC Logistic Regression on test set:\", matthews_corrcoef(y_test, my_pred))\n",
    "print(\"Precision Logistic Regression on test set:\", precision_score(y_test, my_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer_lemma, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression.pkl']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, 'logistic_regression.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps and possibles improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use large pre-trained language model for transfer learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning has greatly impacted computer vision. Using a pre-trained ConvNet on ImageNet as initialization or fine-tuning it to your task at hand has become very common. In NLP we have some neural model pre-trained like ULMFiT. This model provides a Universal Language Model, pre-trained on millions of Wikipedia pages, which we can fine-tune to our specific domain space. Then, we can train a text classification model that leverages the LM’s learned text representations which can learn with very few examples (up to 100x less data).\n",
    "The advantages are that with linguistic model like that it's possible to modelize the semantic of the text and better understand the meaning of the content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a recommendation engine for more than one product category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this kind of approach it's simple to imagine a \"bigger\" engine that can be use to indentify more needs/topics inside the social data and suggest more than one kind of product/item, supporting also a mulitlabelling classification. In fact, if we suppose to create for each of these label a specific binary classifier, each of then trained on a specific domain, is simple to collect all of these models inside an high level \"Black Box\". This approach is like a stacking of ML models and the finals recommendation rules can be obtain by apply a new super-learner model or bussiness logic rules on the predicted probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/stack_model.png\" height=\"700\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
